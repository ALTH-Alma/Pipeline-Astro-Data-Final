{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769db03b-7247-4033-a163-449e0c4634f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from astropy.io import fits\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "import resource\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import resource\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb690e02-cf15-4b18-9494-f9b61dc321e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(image_data):\n",
    "    plt.figure()\n",
    "    plt.imshow(image_data, origin='lower', cmap='magma')\n",
    "    plt.colorbar(label='Intensidad')\n",
    "    plt.title('Imagen del Disco Protoplanetario Normalizada')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.savefig('Image-disk.png')\n",
    "    plt.show()\n",
    "\n",
    "def plotVelocity(vx, vy, titlex, titley):\n",
    "    \n",
    "    # Visualización de las componentes de velocidad\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(vx, origin='lower', aspect='auto', cmap='magma')\n",
    "    plt.colorbar(label='Velocidad')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(titlex)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(vy, origin='lower', aspect='auto', cmap='magma')\n",
    "    plt.colorbar(label='Velocidad')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(titley)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Velocity-disk.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487cda7a-4328-47f2-a83d-d092b4582e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotVelocityField(X, Y, Vx, Vy, npix):\n",
    "    speed = np.sqrt(Vx**2 + Vy**2)\n",
    "    lw = 3.5*speed / speed.max()\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    strm = plt.streamplot(X, Y, Vx, Vy, color=speed, linewidth=lw, cmap='magma')\n",
    "    plt.colorbar(strm.lines, label='Velocidad')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Campo de Velocidad del Disco')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b11ac-78d3-4a1e-87a8-646d96745fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proyectar_velocidades_fargo(file_path_field, out, npix, i_deg, PA_deg):\n",
    "\n",
    "    # Leer coordenadas y velocidades polares\n",
    "    r = np.loadtxt(file_path_field + 'domain_y.dat')[3:-4]\n",
    "    phi = np.loadtxt(file_path_field + 'domain_x.dat')[:-1]\n",
    "    nr, nphi = len(r), len(phi)\n",
    "\n",
    "    Vr = np.fromfile(file_path_field + f'gasvy{out:d}.dat', dtype=np.float64).reshape(nr, nphi)\n",
    "    Vphi = np.fromfile(file_path_field + f'gasvx{out:d}.dat', dtype=np.float64).reshape(nr, nphi)\n",
    "\n",
    "    # Convertir de coordenadas polares a cartesianas\n",
    "    Phi, R = np.meshgrid(phi, r)\n",
    "    X = R * np.cos(Phi)\n",
    "    Y = R * np.sin(Phi)\n",
    "\n",
    "    Vx = Vr * np.cos(Phi) - Vphi * np.sin(Phi)\n",
    "    Vy = Vr * np.sin(Phi) + Vphi * np.cos(Phi)\n",
    "        \n",
    "    # Ángulos en radianes\n",
    "    inc = np.radians(i_deg)  # inclinación\n",
    "    PAr = np.radians(PA_deg)  # posición del eje mayor (PA)\n",
    "    \n",
    "    # Aplicar la inclinación en Y (comprime posiciones y velocidades en ese eje) \n",
    "    Y_incl = Y * np.cos(inc)\n",
    "    Vy_incl = Vy * np.cos(inc)\n",
    "    \n",
    "    # Rotar el sistema para alinear el eje mayor con X\n",
    "    X_rot = X * np.cos(PAr) + Y_incl * np.sin(PAr)\n",
    "    Y_rot = -X * np.sin(PAr) + Y_incl * np.cos(PAr)\n",
    "    \n",
    "    Vx_rot = Vx * np.cos(PAr) + Vy_incl * np.sin(PAr)\n",
    "    Vy_rot = -Vx * np.sin(PAr) + Vy_incl * np.cos(PAr)\n",
    "    \n",
    "    # Interpolación en malla cartesiana uniforme\n",
    "    new_x = np.linspace(X_rot.min(), X_rot.max(), npix)\n",
    "    new_y = np.linspace(Y_rot.min(), Y_rot.max(), npix)\n",
    "    new_X, new_Y = np.meshgrid(new_x, new_y)\n",
    "    \n",
    "    Vx_cartesian = griddata((X_rot.ravel(), Y_rot.ravel()), Vx_rot.ravel(), (new_X, new_Y), method='nearest')\n",
    "    Vy_cartesian = griddata((X_rot.ravel(), Y_rot.ravel()), Vy_rot.ravel(), (new_X, new_Y), method='nearest')\n",
    "    \n",
    "    Vx_cartesian = np.flip(np.squeeze(Vx_cartesian), axis=(0,1))\n",
    "    Vy_cartesian = np.flip(np.squeeze(Vy_cartesian), axis=(0,1))\n",
    "\n",
    "    if pnt:\n",
    "        print(\"Dimensiones Vx, Vy - shape: \", Vx.shape, Vy.shape)\n",
    "        print(\"Vx Max: \", Vx.max(), \" Vx Min: \", Vx.min())\n",
    "        print(\"Vy Max: \", Vy.max(), \" Vy Min: \", Vy.min())\n",
    "        plotVelocity(Vx, Vy, 'Componente de Velocidad X cartesian', \\\n",
    "                     'Componente de Velocidad Y cartesian')\n",
    "\n",
    "        print(\"Nuevas dimensiones X, Y - shape: \", new_X.shape, new_Y.shape)\n",
    "        print(\"Nuevas dimensiones Vx, Vy - shape: \", Vx_cartesian.shape, Vy_cartesian.shape)\n",
    "        print(\"Vx cartesian npix Max: \", Vx_cartesian.max(), \" Vx cartesian npix Min: \", Vx_cartesian.min())\n",
    "        print(\"Vy cartesian npix Max: \", Vy_cartesian.max(), \" Vy cartesian npix Min: \", Vy_cartesian.min())\n",
    "        print(\"Number of NaNs in Vy_cartesian:\", np.isnan(Vx_cartesian).sum())\n",
    "        print(\"Number of NaNs in Vy_cartesian:\", np.isnan(Vy_cartesian).sum())\n",
    "\n",
    "        plotVelocity(Vx_cartesian, Vy_cartesian, 'Componente de Velocidad X cartesian npix', \\\n",
    "                     'Componente de Velocidad Y cartesian npix')\n",
    "\n",
    "        print(\"Imprimiendo campo de velocidades\")\n",
    "        plotVelocityField(new_X, new_Y, Vx_cartesian, Vy_cartesian, npix)\n",
    "\n",
    "    return Vx_cartesian, Vy_cartesian, new_X, new_Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20002ec-5869-4cfe-838f-9c4a5cd66056",
   "metadata": {},
   "source": [
    "## Normalización por disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044a500-6b41-4b60-92f5-7a397c42bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_files_norm(simulation, offset, time_step, npix, err_sim, v_time, \\\n",
    "                         base_path_time, file_time, base_path_field,\\\n",
    "                         normtype, incl, rot, origen):\n",
    "\n",
    "    images_data_norm_tot = []\n",
    "    vfield_data_norm_x_tot = []\n",
    "    vfield_data_norm_y_tot = []\n",
    "    vfield_data_coordinates_tot = []\n",
    "    tag_data = []\n",
    "\n",
    "    for sim in range(simulation):\n",
    "    \n",
    "        if (sim+offset) in err_sim:\n",
    "            continue\n",
    "    \n",
    "        images_data_norm_by_sim = []\n",
    "        tag_data.append([f\"{file_time}\", f\"{origen}_sim_{offset + sim}\"])\n",
    "        \n",
    "        for t in range(1, time_step):\n",
    "        \n",
    "            ###TIME####\n",
    "            # Ruta donde están guardadas las imágenes\n",
    "            file_path_time = f\"{base_path_time}/{file_time}/sim_{sim+offset:01d}/output_{t:01d}/image_out_wl1300.fits\"\n",
    "\n",
    "            hdulist = fits.open(file_path_time, mode='readonly', do_not_scale_image_data=True)\n",
    "            image_data = hdulist[0].data\n",
    "            image_data = np.flipud(image_data)\n",
    "            hdulist.close()\n",
    "            image_data = np.squeeze(image_data)\n",
    "            \n",
    "            if normtype == 'percentil':\n",
    "                # Normalizar datos utilizando percentiles:\n",
    "                p2, p98 = np.percentile(image_data, (2, 98))\n",
    "                image_data_norm = np.clip((image_data - p2) / (p98 - p2), 0, 1)\n",
    "\n",
    "            elif normtype == 'log':\n",
    "                # Normalizar datos utilizando transformación logarítmica:\n",
    "                aux_norm = np.log1p(image_data - image_data.min())\n",
    "                image_data_norm = np.divide(aux_norm, aux_norm.max(), dtype=np.float32)\n",
    "\n",
    "            elif normtype == 'zscore':\n",
    "                # Normalizar datos utilizando Z-Score:\n",
    "                image_data_norm = np.divide((image_data - np.mean(image_data)), np.std(image_data), dtype=np.float32)\n",
    "\n",
    "            elif normtype == 'min-max':\n",
    "                # Normalizar datos utilizando Norm min-max (0-1):\n",
    "                aux_norm_1 = image_data - image_data.min()\n",
    "                aux_norm_2 = image_data.max() - image_data.min()\n",
    "                image_data_norm = np.divide(aux_norm_1, aux_norm_2, dtype=np.float32)\n",
    "                \n",
    "            elif normtype == 'menos1_1':\n",
    "                # Normalizar datos utilizando Norm min-max (-1 , 1):\n",
    "                aux_norm_1 = image_data - image_data.min()\n",
    "                aux_norm_2 = image_data.max() - image_data.min()\n",
    "                image_data_norm = 2 * np.divide(aux_norm_1, aux_norm_2, dtype=np.float32) - 1\n",
    "                \n",
    "            else:\n",
    "                print(\"Nortype error - exit\")\n",
    "                return\n",
    "                \n",
    "            images_data_norm_by_sim.append(image_data_norm)\n",
    "\n",
    "            if(t == (time_step-1) and pnt): \n",
    "                print(f'IMAGEN ORIGINAL')\n",
    "                plotImage(image_data)\n",
    "                print(f'IMAGEN NORMALIZADA')\n",
    "                print(image_data_norm.shape)\n",
    "                plotImage(image_data_norm)\n",
    "                print(f'std: {np.std(image_data)} and mean: {np.mean(image_data)} of data image')\n",
    "                print(f'std: {np.std(image_data_norm)} and mean: {np.mean(image_data_norm)} of normalizate data image')\n",
    "                print(\"\\n\\n\")\n",
    "    \n",
    "        images_data_norm_tot.append(images_data_norm_by_sim)\n",
    "        \n",
    "        ###VELOCITY###\n",
    "        # Ruta donde estan guardadas las velocidades\n",
    "        file_path_field = f'{base_path_field}/sim_{(sim+offset):01d}/'\n",
    "\n",
    "        # Obtener velocidades del gas (gas1) del ultimo paso de tiempo (cambiar función a gusto)\n",
    "        vfield_data_x, vfield_data_y, coordinates_x, coordinates_y = proyectar_velocidades_fargo(file_path_field, v_time, npix, incl, rot)\n",
    "    \n",
    "        vfield_data_coordinates_par = []\n",
    "    \n",
    "        #--------------------------vx-vy-------------------------------------\n",
    "        if normtype == 'percentil':\n",
    "            # Normalizar datos utilizando percentiles:\n",
    "            p2_vx, p98_vx = np.percentile(vfield_data_x, (2, 98))\n",
    "            vfield_data_norm_x = np.clip((vfield_data_x - p2_vx) / (p98 - p2_vx), 0, 1)\n",
    "\n",
    "            p2_vy, p98_vy = np.percentile(vfield_data_y, (2, 98))\n",
    "            vfield_data_norm_y = np.clip((vfield_data_y - p2_vy) / (p98 - p2_vy), 0, 1)\n",
    "\n",
    "        elif normtype == 'log':\n",
    "            # Normalizar datos utilizando transformación logarítmica:\n",
    "            aux_norm_vx = np.log1p(vfield_data_x - vfield_data_x.min())\n",
    "            vfield_data_norm_x = np.divide(aux_norm_vx, aux_norm_vx.max(), dtype=np.float32)\n",
    "\n",
    "            aux_norm_vy = np.log1p(vfield_data_y - vfield_data_y.min())\n",
    "            vfield_data_norm_y = np.divide(aux_norm_vy, aux_norm_vy.max(), dtype=np.float32)\n",
    "\n",
    "        elif normtype == 'zscore':\n",
    "            # Normalizar datos utilizando Z-Score:\n",
    "            vfield_data_norm_x = np.divide((vfield_data_x - np.mean(vfield_data_x)), np.std(vfield_data_x), dtype=np.float32)\n",
    "            \n",
    "            vfield_data_norm_y = np.divide((vfield_data_y - np.mean(vfield_data_y)), np.std(vfield_data_y), dtype=np.float32)\n",
    "\n",
    "        elif normtype == 'min-max':\n",
    "            # Normalizar datos utilizando Norm min-max (0-1)\n",
    "            aux_norm_1 = vfield_data_x - vfield_data_x.min()\n",
    "            aux_norm_2 = vfield_data_x.max() - vfield_data_x.min()\n",
    "            vfield_data_norm_x = np.divide(aux_norm_1, aux_norm_2, dtype=np.float32)\n",
    "\n",
    "            aux_norm_1 = vfield_data_y - vfield_data_y.min()\n",
    "            aux_norm_2 = vfield_data_y.max() - vfield_data_y.min()\n",
    "            vfield_data_norm_y = np.divide(aux_norm_1, aux_norm_2, dtype=np.float32)\n",
    "\n",
    "        elif normtype == 'menos1_1':\n",
    "            # Normalizar datos utilizando Norm min-max (-1 , 1)\n",
    "            aux_norm_1 = vfield_data_x - vfield_data_x.min()\n",
    "            aux_norm_2 = vfield_data_x.max() - vfield_data_x.min()\n",
    "            vfield_data_norm_x = 2 * np.divide(aux_norm_1, aux_norm_2, dtype=np.float32) - 1\n",
    "\n",
    "            aux_norm_1 = vfield_data_y - vfield_data_y.min()\n",
    "            aux_norm_2 = vfield_data_y.max() - vfield_data_y.min()\n",
    "            vfield_data_norm_y = 2 * np.divide(aux_norm_1, aux_norm_2, dtype=np.float32) - 1\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            print(\"Nortype error - exit\")\n",
    "            return\n",
    "        \n",
    "        vfield_data_norm_x_tot.append(vfield_data_norm_x)\n",
    "    \n",
    "        vfield_data_norm_y_tot.append(vfield_data_norm_y)\n",
    "    \n",
    "        if pnt:\n",
    "            plotVelocity(vfield_data_norm_x, vfield_data_norm_y, 'Componente de Velocidad Horizontal Normalizada', \\\n",
    "                     'Componente de Velocidad Vertical Normalizada')\n",
    "            print(f'std: {np.std(vfield_data_x)} and mean: {np.mean(vfield_data_x)} of data vx')\n",
    "            print(f'std: {np.std(vfield_data_y)} and mean: {np.mean(vfield_data_y)} of data vy')\n",
    "            print(f'std: {np.std(vfield_data_norm_x)} and mean: {np.mean(vfield_data_norm_x)} of normalizate data vx')\n",
    "            print(f'std: {np.std(vfield_data_norm_y)} and mean: {np.mean(vfield_data_norm_y)} of normalizate data vy')\n",
    "    \n",
    "        vfield_data_coordinates_par.append(coordinates_x)\n",
    "        vfield_data_coordinates_par.append(coordinates_y)\n",
    "        vfield_data_coordinates_tot.append(vfield_data_coordinates_par)\n",
    "        \n",
    "    images_data_norm_tot_np = np.asarray(images_data_norm_tot)\n",
    "    vfield_data_norm_x_tot_np = np.asarray(vfield_data_norm_x_tot)\n",
    "    vfield_data_norm_y_tot_np = np.asarray(vfield_data_norm_y_tot)\n",
    "    vfield_data_coordinates_tot_np = np.asarray(vfield_data_coordinates_tot)\n",
    "    tag_data_np = np.array(tag_data, dtype=str)\n",
    "\n",
    "    return images_data_norm_tot_np, vfield_data_norm_x_tot_np, vfield_data_norm_y_tot_np, vfield_data_coordinates_tot_np, tag_data_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a98b9-4a2f-4520-86e4-c0b5c1093b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4659a-50e3-44bf-b3f6-d38820d8ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________________________________GENERAL SETTING___________________________________\n",
    "\n",
    "##IMAGES SETTING###\n",
    "npix = 128 # Tamaño de pixel\n",
    "zscore = 'zscore'\n",
    "min_max = 'min-max'\n",
    "norm_menos1_1 = 'menos1_1'\n",
    "\n",
    "normtype = norm_menos1_1\n",
    "fieldtype = 'cartesian'\n",
    "num_data = 5\n",
    "output_np_file_name_img = f'./numpyFile_sim_images_{normtype}_{fieldtype}_v{num_data}'\n",
    "output_np_file_name_tag = f'./numpyFile_sim_tag_{normtype}_{fieldtype}_v{num_data}'\n",
    "\n",
    "##VELOCITY SETTING###\n",
    "time_step = 20 #20 # Numero de imagenes por disco simulado \n",
    "v_time = 19 #19 # Indice de la salida por simulacion de fargo para obtener el campo de velocidades (19 last) - Obtengo el campo del ultimo tiempo.\n",
    "output_np_file_name_vel_x = f'./numpyFile_sim_velocity_x_{normtype}_{fieldtype}_v{num_data}'\n",
    "output_np_file_name_vel_y = f'./numpyFile_sim_velocity_y_{normtype}_{fieldtype}_v{num_data}'\n",
    "output_np_file_name_coordinates_vel = f'./numpyFile_sim_velocity_coordinates_{normtype}_{fieldtype}_v{num_data}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir indice de archivos con errores por configuración\n",
    "err_sim_l1 = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "err_sim_l2 = [10, 11, 12, 13, 14, 15]\n",
    "err_sim_l3 = [20, 21, 22, 23, 24, 25]\n",
    "err_sim_l4 = [30, 31, 32, 33, 34, 35]\n",
    "err_sim_l6 = [40, 41, 42, 43, 44, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11064b0-3227-4172-afba-5e14e8c4453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_limit, hard_limit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print(f\"Límite de archivos abiertos: {soft_limit}/{hard_limit}\")\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (4096, hard_limit))\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9883a3a-7a0a-4a87-9ee4-c8e27d489d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones de las diferentes inclinacion y rotaciones o carpetas\n",
    "configuraciones = [\n",
    "    {   #RT\n",
    "        'path_time': '/srv/nas02/alma/Radmc_data/out_leia_v2',\n",
    "        'file_time': 'All_sim_pix128',\n",
    "        'sim': 2000,\n",
    "        'offset': 0,\n",
    "        'path_field': '/srv/nas02/alma/Fargo_data/outputs/out_leia_v2',\n",
    "        'incl': 0,\n",
    "        'rot': 0,\n",
    "        'err': err_sim_l1,\n",
    "        'origen': 'leia'\n",
    "    },\n",
    "    {   #RT_2\n",
    "        'path_time': '/srv/nas02/alma/Radmc_data/out_leia_v2',\n",
    "        'file_time': 'All_sim_pix128_incl30_rot45',\n",
    "        'sim': 2000,\n",
    "        'offset': 0,\n",
    "        'path_field': '/srv/nas02/alma/Fargo_data/outputs/out_leia_v2',\n",
    "        'incl': 30,\n",
    "        'rot': 45,\n",
    "        'err': err_sim_l2,\n",
    "        'origen': 'leia'\n",
    "    },\n",
    "    {   #RT_3\n",
    "        'path_time': '/srv/nas02/alma/Radmc_data/out_leia_v2',\n",
    "        'file_time': 'All_sim_pix128_incl60_rot215',\n",
    "        'sim': 2000,\n",
    "        'offset': 0,\n",
    "        'path_field': '/srv/nas02/alma/Fargo_data/outputs/out_leia_v2',\n",
    "        'incl': 60,\n",
    "        'rot': 215,\n",
    "        'err': err_sim_l3,\n",
    "        'origen': 'leia'\n",
    "    },\n",
    "    {   #RT_4\n",
    "        'path_time': '/srv/nas02/alma/Radmc_data/out_leia_v2',\n",
    "        'file_time': 'All_sim_pix128_incl75_rot135',\n",
    "        'sim': 2000,\n",
    "        'offset': 0,\n",
    "        'path_field': '/srv/nas02/alma/Fargo_data/outputs/out_leia_v2',\n",
    "        'incl': 75,\n",
    "        'rot': 135,\n",
    "        'err': err_sim_l4,\n",
    "        'origen': 'leia'\n",
    "    },\n",
    "    {   #RT_6\n",
    "        'path_time': '/srv/nas02/alma/Radmc_data/out_leia_v2',\n",
    "        'file_time': 'All_sim_pix128_incl50_rot315',\n",
    "        'sim': 2000,\n",
    "        'offset': 0,\n",
    "        'path_field': '/srv/nas02/alma/Fargo_data/outputs/out_leia_v2',\n",
    "        'incl': 50,\n",
    "        'rot': 315,\n",
    "        'err': err_sim_l6,\n",
    "        'origen': 'leia'\n",
    "    },\n",
    "]\n",
    "\n",
    "all_images = []\n",
    "all_vfield_x = []\n",
    "all_vfield_y = []\n",
    "all_vfield_coords = []\n",
    "all_tags = []\n",
    "\n",
    "for i, config in enumerate(configuraciones):\n",
    "\n",
    "    print(f\"\\n==== Procesando configuración l{i+1}: incl={config['incl']}, rot={config['rot']} ====\")\n",
    "\n",
    "    images_np, vfield_x_np, vfield_y_np, coords_np, tags_np = get_numpy_files_norm(\n",
    "        config['sim'], config['offset'], time_step,\n",
    "        npix, config['err'], v_time,\n",
    "        config['path_time'], config['file_time'],\n",
    "        config['path_field'], normtype,\n",
    "        config['incl'], config['rot'], config['origen']\n",
    "    )\n",
    "\n",
    "    print(f\"Imágenes shape: {images_np.shape}\")\n",
    "    print(f\"Velocidad X shape: {vfield_x_np.shape}\")\n",
    "    print(f\"Velocidad Y shape: {vfield_y_np.shape}\")\n",
    "    print(f\"Coordenadas shape: {coords_np.shape}\")\n",
    "    print(f\"Tags shape: {tags_np.shape}\")\n",
    "\n",
    "    all_images.append(images_np)\n",
    "    all_vfield_x.append(vfield_x_np)\n",
    "    all_vfield_y.append(vfield_y_np)\n",
    "    all_vfield_coords.append(coords_np)\n",
    "    all_tags.append(tags_np)\n",
    "\n",
    "combined_images = np.concatenate(all_images, axis=0)\n",
    "combined_vfield_x = np.concatenate(all_vfield_x, axis=0)\n",
    "combined_vfield_y = np.concatenate(all_vfield_y, axis=0)\n",
    "combined_vfield_coordinates = np.concatenate(all_vfield_coords, axis=0)\n",
    "combined_tags = np.concatenate(all_tags, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b1ad5-4478-4db0-a70e-e6db62106a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== SAVING numpy files All combinados =====\")\n",
    "print(combined_images.shape)\n",
    "print(combined_vfield_x.shape)\n",
    "print(combined_vfield_y.shape)\n",
    "print(combined_vfield_coordinates.shape)\n",
    "print(combined_tags.shape)\n",
    "\n",
    "np.save(output_np_file_name_img, combined_images)\n",
    "np.save(output_np_file_name_vel_x, combined_vfield_x)\n",
    "np.save(output_np_file_name_vel_y, combined_vfield_y)\n",
    "np.save(output_np_file_name_coordinates_vel, combined_vfield_coordinates)\n",
    "np.save(output_np_file_name_tag, combined_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea01f6d-bd9d-4099-b391-3563850f5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar nuevos archivos a los existentes (hacer más rápida la lectura)\n",
    "base_file = 3\n",
    "new_file = 4\n",
    "\n",
    "# Cargar los archivos base\n",
    "images = np.load(f'numpyFile_sim_images_menos1_1_cartesian_{base_file}.npy')\n",
    "vel_x = np.load(f'numpyFile_sim_velocity_x_menos1_1_cartesian_{base_file}.npy')\n",
    "vel_y = np.load(f'numpyFile_sim_velocity_y_menos1_1_cartesian_{base_file}.npy')\n",
    "coords = np.load(f'numpyFile_sim_velocity_coordinates_menos1_1_cartesian_{base_file}.npy')\n",
    "tags = np.load(f'numpyFile_sim_tag_menos1_1_cartesian_{base_file}.npy')\n",
    "\n",
    "print(\"Original shapes:\")\n",
    "print(\"images.shape:\", images.shape)\n",
    "print(\"vel_x.shape:\", vel_x.shape)\n",
    "print(\"vel_y.shape:\", vel_y.shape)\n",
    "print(\"coords.shape:\", coords.shape)\n",
    "print(\"tags.shape:\", tags.shape)\n",
    "\n",
    "# Cargar los nuevos archivos\n",
    "new_images = np.load(f'numpyFile_sim_images_menos1_1_cartesian_{new_file}.npy')\n",
    "new_vel_x = np.load(f'numpyFile_sim_velocity_x_menos1_1_cartesian_{new_file}.npy')\n",
    "new_vel_y = np.load(f'numpyFile_sim_velocity_y_menos1_1_cartesian_{new_file}.npy')\n",
    "new_coords = np.load(f'numpyFile_sim_velocity_coordinates_menos1_1_cartesian_{new_file}.npy')\n",
    "new_tags = np.load(f'numpyFile_sim_tag_menos1_1_cartesian_{new_file}.npy')\n",
    "\n",
    "print(\"\\nNew data shapes:\")\n",
    "print(\"new_images.shape:\", new_images.shape)\n",
    "print(\"new_vel_x.shape:\", new_vel_x.shape)\n",
    "print(\"new_vel_y.shape:\", new_vel_y.shape)\n",
    "print(\"new_coords.shape:\", new_coords.shape)\n",
    "print(\"new_tags.shape:\", new_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e272dd4-783c-487d-a9e9-92c9698ce958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar los datos\n",
    "images = np.concatenate((images, new_images), axis=0)\n",
    "vel_x = np.concatenate((vel_x, new_vel_x), axis=0)\n",
    "vel_y = np.concatenate((vel_y, new_vel_y), axis=0)\n",
    "coords = np.concatenate((coords, new_coords), axis=0)\n",
    "tags = np.concatenate((tags, new_tags), axis=0)\n",
    "\n",
    "print(\"\\nConcatenated shapes:\")\n",
    "print(\"images.shape:\", images.shape)\n",
    "print(\"vel_x.shape:\", vel_x.shape)\n",
    "print(\"vel_y.shape:\", vel_y.shape)\n",
    "print(\"coords.shape:\", coords.shape)\n",
    "print(\"tags.shape:\", tags.shape)\n",
    "\n",
    "# Guardar los archivos combinados sobrescribiendo el archivo base\n",
    "np.save(f'numpyFile_sim_images_menos1_1_cartesian_{base_file}.npy', images)\n",
    "np.save(f'numpyFile_sim_velocity_x_menos1_1_cartesian_{base_file}.npy', vel_x)\n",
    "np.save(f'numpyFile_sim_velocity_y_menos1_1_cartesian_{base_file}.npy', vel_y)\n",
    "np.save(f'numpyFile_sim_velocity_coordinates_menos1_1_cartesian_{base_file}.npy', coords)\n",
    "np.save(f'numpyFile_sim_tag_menos1_1_cartesian_{base_file}.npy', tags)\n",
    "\n",
    "print(\"\\nArchivos combinados y guardados exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5f9bd-0bb3-4db1-9415-2ba11fda52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file = 3\n",
    "\n",
    "# Cargar los archivos base\n",
    "images = np.load(f'numpyFile_sim_images_menos1_1_cartesian_{base_file}.npy')\n",
    "vel_x = np.load(f'numpyFile_sim_velocity_x_menos1_1_cartesian_{base_file}.npy')\n",
    "vel_y = np.load(f'numpyFile_sim_velocity_y_menos1_1_cartesian_{base_file}.npy')\n",
    "coords = np.load(f'numpyFile_sim_velocity_coordinates_menos1_1_cartesian_{base_file}.npy')\n",
    "tags = np.load(f'numpyFile_sim_tag_menos1_1_cartesian_{base_file}.npy')\n",
    "\n",
    "print(\"Original shapes:\")\n",
    "print(\"images.shape:\", images.shape)\n",
    "print(\"vel_x.shape:\", vel_x.shape)\n",
    "print(\"vel_y.shape:\", vel_y.shape)\n",
    "print(\"coords.shape:\", coords.shape)\n",
    "print(\"tags.shape:\", tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948bbbe7-c420-4301-b73b-71236ef73d0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normalización completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13917a-3c51-4fd1-a8fa-366a65220f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion completa, considerando todos los datos (Se probo pero se descarto) \n",
    "combined_images = images\n",
    "combined_vfield_x = vel_x\n",
    "combined_vfield_y = vel_y\n",
    "\n",
    "if normtype == 'min-max':\n",
    "    print(\"-------NORMALIZANDO MIN_MAX (0-1)-------\")\n",
    "    # Normalización usando los valores min-max globales (0-1):\n",
    "    # Images:\n",
    "    aux_norm_1 = combined_images - combined_images.min()\n",
    "    aux_norm_2 = combined_images.max() - combined_images.min()\n",
    "    combined_images_norm = np.divide(aux_norm_1, aux_norm_2, dtype=np.float32)\n",
    "    # Vx:\n",
    "    aux_norm_x_1 = combined_vfield_x - combined_vfield_x.min()\n",
    "    aux_norm_x_2 = combined_vfield_x.max() - combined_vfield_x.min()\n",
    "    combined_vfield_x_norm = np.divide(aux_norm_x_1, aux_norm_x_2, dtype=np.float32)\n",
    "    # Vy:\n",
    "    aux_norm_y_1 = combined_vfield_y - combined_vfield_y.min()\n",
    "    aux_norm_y_2 = combined_vfield_y.max() - combined_vfield_y.min()\n",
    "    combined_vfield_y_norm = np.divide(aux_norm_y_1, aux_norm_y_2, dtype=np.float32)\n",
    "\n",
    "elif normtype == 'percentil':\n",
    "    print(\"-------NORMALIZANDO PERCENTIL-------\")\n",
    "    # Normalizar datos utilizando percentiles:\n",
    "    # Images:\n",
    "    p2, p98 = np.percentile(combined_images, (2, 98))\n",
    "    combined_images_norm = np.clip((combined_images - p2) / (p98 - p2), 0, 1)\n",
    "    # Vx:\n",
    "    p2_vx, p98_vx = np.percentile(combined_vfield_x, (2, 98))\n",
    "    combined_vfield_x_norm = np.clip((combined_vfield_x - p2_vx) / (p98 - p2_vx), 0, 1)\n",
    "    # Vy:\n",
    "    p2_vy, p98_vy = np.percentile(combined_vfield_y, (2, 98))\n",
    "    combined_vfield_y_norm = np.clip((combined_vfield_y - p2_vy) / (p98 - p2_vy), 0, 1)\n",
    "\n",
    "elif normtype == 'log':\n",
    "    print(\"-------NORMALIZANDO LOG-------\")\n",
    "    # Normalizar datos utilizando transformación logarítmica:\n",
    "    # Images:\n",
    "    aux_norm = np.log1p(combined_images - combined_images.min())\n",
    "    combined_images_norm = np.divide(aux_norm, aux_norm.max(), dtype=np.float32)\n",
    "    # Vx:\n",
    "    aux_norm_vx = np.log1p(combined_vfield_x - combined_vfield_x.min())\n",
    "    combined_vfield_x_norm = np.divide(aux_norm_vx, aux_norm_vx.max(), dtype=np.float32)\n",
    "    # Vy:\n",
    "    aux_norm_vy = np.log1p(combined_vfield_y - combined_vfield_y.min())\n",
    "    combined_vfield_y_norm = np.divide(aux_norm_vy, aux_norm_vy.max(), dtype=np.float32)\n",
    "\n",
    "elif normtype == 'zscore':\n",
    "    print(\"-------NORMALIZANDO ZSCORE-------\")\n",
    "    # Normalizar datos utilizando Z-Score:\n",
    "    # Images:\n",
    "    combined_images_norm = np.divide((combined_images - np.mean(combined_images)), np.std(combined_images), dtype=np.float32)\n",
    "    # Vx:\n",
    "    combined_vfield_x_norm = np.divide((combined_vfield_x - np.mean(combined_vfield_x)), np.std(combined_vfield_x), dtype=np.float32)\n",
    "    # Vy:\n",
    "    combined_vfield_y_norm = np.divide((combined_vfield_y - np.mean(combined_vfield_y)), np.std(combined_vfield_y), dtype=np.float32)\n",
    "\n",
    "elif normtype == 'menos1_1':\n",
    "    print(\"-------NORMALIZANDO -1 a 1-------\")\n",
    "    # Normalización usando los valores min-max globales (0-1):\n",
    "    # Images:\n",
    "    aux_norm_1 = combined_images - combined_images.min()\n",
    "    aux_norm_2 = combined_images.max() - combined_images.min()\n",
    "    combined_images_norm = 2 * np.divide(aux_norm_1, aux_norm_2, dtype=np.float32) - 1\n",
    "    # Vx:\n",
    "    aux_norm_x_1 = combined_vfield_x - combined_vfield_x.min()\n",
    "    aux_norm_x_2 = combined_vfield_x.max() - combined_vfield_x.min()\n",
    "    combined_vfield_x_norm = 2 * np.divide(aux_norm_x_1, aux_norm_x_2, dtype=np.float32) - 1\n",
    "    # Vy:\n",
    "    aux_norm_y_1 = combined_vfield_y - combined_vfield_y.min()\n",
    "    aux_norm_y_2 = combined_vfield_y.max() - combined_vfield_y.min()\n",
    "    combined_vfield_y_norm = 2 * np.divide(aux_norm_y_1, aux_norm_y_2, dtype=np.float32) - 1\n",
    "\n",
    "elif normtype == 'transformer_torch':\n",
    "    print(\"-------NORMALIZANDO torch transfor-------\")\n",
    "    \n",
    "    \n",
    "else: \n",
    "    print(\"Error normtype - data sin normalizar\")\n",
    "    combined_images_norm = combined_images\n",
    "    combined_vfield_x_norm = combined_vfield_x\n",
    "    combined_vfield_y_norm = combined_vfield_y\n",
    "\n",
    "\n",
    "#Probar normalizacion:\n",
    "id = 0\n",
    "print(f'IMAGEN ORIGINAL')\n",
    "plotImage(combined_images_norm[id, 18])\n",
    "print(f'VELOCIDADES NORMALIZADAS')\n",
    "plotVelocity(combined_vfield_x_norm[id], combined_vfield_y_norm[id], 'Componente de Velocidad Horizontal Cartesiana Normalizada', \\\n",
    "                     'Componente de Velocidad Vertical Cartesiana Normalizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cff04-556c-4aaa-af73-9fde742aa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n ===== SAVING numpy files All\")\n",
    "print(combined_images_norm.shape)\n",
    "print(combined_vfield_x_norm.shape)\n",
    "print(combined_vfield_y_norm.shape)\n",
    "\n",
    "np.save(output_np_file_name_img, combined_images_norm)\n",
    "np.save(output_np_file_name_vel_x, combined_vfield_x_norm)\n",
    "np.save(output_np_file_name_vel_y, combined_vfield_y_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
